<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Value Sensitive Design - Morgan Klaus Scheuerman</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="/assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
							<header id="header">
								<ul class="icons">
									<div class="header-left"><li>
										<p style="font-size:1vw;"><a href="/readings.html"><span class="icon solid fa-arrow-left"> Back to Reading List</span></a></p>
									</li></div>
									<li><b>SOCIAL</b><img src="https://static.wixstatic.com/media/697bc8_3b4cf3d1a498494e8b6e097004ae72b1~mv2.gif" height="12px" width="12px"></li>
									<li><a href="https://twitter.com/morganklauss" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="https://www.instagram.com/atravelingrad/" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="https://medium.com/@morganklausscheuerman" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
									<li><a href="https://www.linkedin.com/in/morgan-scheuerman/" class="icon brands fa-linkedin" aria-label="LinkedIn"></a></li>
									<li><a href="https://github.com/morganklauss" class="icon brands fa-github"><span class="label">Github</span></a></li>
								</ul>
							</header>

							<!-- Content -->
								<section>

									<h2>Race After Technology: Abolitionist Tools for the New Jim Code</h2>
									
									Ruha Benjamin. 2019. Race After Technology: Abolitionist Tools for the New Jim Code. John Wiley & Sons. <a href="https://www.wiley.com/en-us/Race+After+Technology:+Abolitionist+Tools+for+the+New+Jim+Code-p-9781509526437" target="_blank">ISBN: 978-1-509-52643-7</a>
									<br><br>

									<h3>Introduction: The New Jim Code</h3>

									The introduction to Race After Technology introduces the reader to the underlying social inequities embedded
									 within our society that are also present in our technologies - and, always has been. My notes are structured by
									  important concepts that jumped out at me during this chapter.

									  <br><br>

									<h4>Social and Technological Codes</h4>

									Benjamin starts out by introducing the notion of names as data. Cultural, social, and historical data.
									Naming is tied to many aspects of our identities and histories, and also perceived and labelled by outsiders - 
									including outside technologies. For example, in marketing, security, resume parsing, and policing.
									The normalization of white names and the seeming invisibility of white culture offers
									immunity to discrimination, othering those that stand out against this normalization (e.g., 
									applicant discrimination based on names) (pg. 4) Technologies reify and amplify these types of culturally encoded biases.

									<br><br>
									Benjamin compared social codes to the codes of data and technology. Social coding, like 
									racially coded names being synonymous with risk, are reinforced through computer codes, such
									as California's gang database (which even includes names of babies). Both social codes and 
									computer code are difficult and arduous to change and laden with political power.
									Race is not simply inherent in technology, but operates as a technology.
									<br><br>

									<h4>The New Jim Code</h4>

									Benjamin defined the New Jim Code as: "The employment of new technologies that reflect and reproduce 
									existing inequities but that are promoted and perceived as more objective 
									and progressive than the discriminatory systems of a previous era." (pg. 5-6)
									<br><br>

									Benjamin introduces the book not by focusing on some "sinister story of racist programmers 
									scheming in the dark corners of the web," but rather, "that the desire for objectivity, efficiency,
									 profitability, and progress" (pg. 7) contributes to bias and inequity in technology. Throughout the book,
									 she reviews technologies that "explicitly amplify hierarchies, ... ignore and thus replicate social 
									 divisions, and ... aim to fix racial bias but end up doing the opposite" (pg. 8). 

									<dl>
										<dt>
											Four Dimensions of the New Jim Code:
										</dt>
										<dd>
										<ul>
											<li>
												<b>Engineered inequity</b>: the explicit amplification of social hierarchies.
											</li>
											<li><b>Default discrimination:</b> how discrimination grows out of socially and historically ignorant design processes 
											</li>
											<li>
												<b>Coded exposure:</b> how "being watched (but not seen)" (pg. 47) enables differing forms of visibility
											</li>
											<li>
												<b>Technological benevolence:</b> tech products that offer fixes for social bias yet still reproduce or deepen
											</li>
										</ul>
										</dd>
									</dl>

									<h4>"Objective" Code and the Monetization of Identity</h4>
									 
									 Benjamin argues that the 
									 "datification of injustice" (pg. 8) is not simply attributed to some bygone era, but also weaponized through 
									 the notion of "progress." She discusses how the ethos of large tech corporations have become public 
									 policy decisions, and how data-sharing has created a more efficient method of marginalization. Diversity is monetized,
									 while the needs of Black users are widely unconsidered (as in the example of not bothering to include African American
									  English in Siri's dialect training) (pg. 28). Through targeted and "personalized" algorithmic advertising, 
									  "diversity" is shallowly represented at the surface. 
									  <br><br>

									  "Economic recognition is a ready but inadequate proxy for political representation and social power," (pg. 19) Benjamin writes. 
									  "Celebrating diversity, in this way, usually avoids sober truth-telling so as not to ruin the party" (pg. 20). "Automated systems are alluring because they seem to remove the burden from gatekeepers ... Profit maximization, in short, 
									  is rebranded as bias minimization" (pg. 30).
									  <br><br>

									  Human biases are often positioned as fixable or overcomed by technological "progress." Benjamin states:
									  "Vows of colorblindness are not necessary to shield coded inqeuity if we believe that scientifically
									 calculated differences are somehow superior to crude human bias" (pg. 21). Thus, if we believe technology is inherently
									 objective, we can replicate social inequality while paying it no mind. This way of viewing technology also
									 ignores the roles and intentions of its creators:
									 "The notion that tech bias is 'unintentional' or 'unconscious' obsceres the reality - that there is no 
									 way to create something without intention and intended user in mind" (pg. 28).
									 <br><br>

									 <h4>Black Boxes Operationalize and Obscure Inequality</h4> 

									 Race is not simply inherent in technology, but operates as a technology. 									 
									 The operationalization of identity and identity proxies in
									 algorithmic black boxes becomes more difficult to contest, and more efficient at operationalizing inequality (pg. 33).
									 <br><br>

									 <h4>A Thin Description Approach</h4>

									 Thin description as "being racialized is 'to be encountered as a surface'" (pg. 45)
									 Pushing back against the notion of all-knowing analysis, but an acknowledgment of the changing 
									 surface of "coded inequity" in technological systems and social systems.

									
									<!-- <h3>Further Reading</h3>

									<ul>
										<li>
										
										</li>
									</ul> -->


								</section>

						</div>
					</div>

				<!-- Sidebar -->
				<div id="sidebar">
					<div class="inner">

						<!-- Menu -->
						<section>
								<header class="main">
									<center><a href="#" class="image"><img src="/images/mainphoto.jpg" alt="" width="200" height="200"/></a>								
									<h1>Morgan Klaus Scheuerman</h1>
								<article>
									<p>PhD Student in <i>Information Science</i> at
									University of Colorado Boulder
									</p>
								</center>
								</article>
								</header>
								<header class="major">
						</section>
						<nav id="menu">
								<ul>
									<li><a href="/index.html">Home</a></li>
									<li><a href="/pdfs/misc/ScheuermanCV-May2020.pdf">CV</a></li>
									<li><a href="/contact.html">Contact</a></li>
									<li><a href="/research.html">Research</a></li>
									<li><a href="/news.html">News</a></li>
									<li><a href="/blog.html">Blog</a></li>
									<li>
										<span class="opener">Projects</span>
										<ul>
											<li><a href="/gender-guidelines.html">HCI Gender Guidelines</a></li>
											<li><a href="/readings.html">Reading List</a></li>
										</ul>
									</li>
							</nav>
						<!--Section-->
						<section>
							<center><a href="/gender-guidelines.html" class="button big">HCI Gender Guidelines</a></center>

							<br>
						<!-- Footer -->
							<footer id="footer">
								<p class="copyright">&copy; Morgan Klaus Scheuerman. 2020. All rights reserved.
									Design adpted from <a href="https://html5up.net">HTML5 UP</a>.</p>
							</footer>

					</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="/assets/js/jquery.min.js"></script>
			<script src="/assets/js/browser.min.js"></script>
			<script src="/assets/js/breakpoints.min.js"></script>
			<script src="/assets/js/util.js"></script>
			<script src="/assets/js/main.js"></script>

	</body>
</html>